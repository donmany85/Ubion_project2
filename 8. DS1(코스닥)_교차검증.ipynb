{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.metrics import accuracy_score,f1_score,recall_score,precision_score,confusion_matrix,ConfusionMatrixDisplay,roc_curve,roc_auc_score,precision_recall_curve\n",
    "from sklearn.ensemble import RandomForestClassifier , StackingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression,Lasso\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.model_selection import cross_val_score,GridSearchCV\n",
    "\n",
    "# 한글 깨짐 방지\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = pd.read_csv('./datasets/KOSDAQ_DATA.csv', index_col=0)\n",
    "kk = kk.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    788\n",
       "1     31\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk[kk['회계년도'] == '2011/12']['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    805\n",
       "1     21\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk[kk['회계년도'] == '2012/12']['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    845\n",
       "1     14\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk[kk['회계년도'] == '2013/12']['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    891\n",
       "1     13\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk[kk['회계년도'] == '2014/12']['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    944\n",
       "1     10\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk[kk['회계년도'] == '2015/12']['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1008\n",
       "1       7\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk[kk['회계년도'] == '2016/12']['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1075\n",
       "1      11\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk[kk['회계년도'] == '2017/12']['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1157\n",
       "1       6\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk[kk['회계년도'] == '2018/12']['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1230\n",
       "1      12\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk[kk['회계년도'] == '2019/12']['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./datasets/KOSDAQ+KOSPI_TRAIN_DATA.csv', index_col=0)\n",
    "train_df = train_df.iloc[:,2:]\n",
    "test_df = pd.read_csv('./datasets/KOSDAQ+KOSPI_TEST1_DATA.csv', index_col=0)\n",
    "test_df = test_df.iloc[:,2:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 코스닥 + 코스피"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 교차검증 1 데이터 셋\n",
    "kk_1112 = kk[(kk['회계년도'] <= '2012/12') & (kk['회계년도'] >= '2011/12')]\n",
    "kk_1319 = kk[(kk['회계년도'] <= '2019/12') & (kk['회계년도'] >= '2013/12')]\n",
    "# 교차검증 2 데이터 셋\n",
    "kk_1213 = kk[(kk['회계년도'] <= '2013/12') & (kk['회계년도'] >= '2012/12')]\n",
    "kk_111419 = kk[(kk['회계년도'] <= '2019/12') & (kk['회계년도'] >= '2014/12') | (kk['회계년도'] == '2011/12')]\n",
    "# 교차검증 3 데이터 셋\n",
    "kk_1314 = kk[(kk['회계년도'] <= '2014/12') & (kk['회계년도'] >= '2013/12')]\n",
    "kk_11121519 = kk[(kk['회계년도'] <= '2019/12') & (kk['회계년도'] >= '2015/12') | (kk['회계년도'] >= '2011/12') & (kk['회계년도'] <= '2012/12')]\n",
    "# 교차검증 4 데이터 셋\n",
    "kk_1415 = kk[(kk['회계년도'] <= '2015/12') & (kk['회계년도'] >= '2014/12')]\n",
    "kk_11131619 = kk[(kk['회계년도'] <= '2019/12') & (kk['회계년도'] >= '2016/12') | (kk['회계년도'] >= '2011/12') & (kk['회계년도'] <= '2013/12')]\n",
    "# 교차검증 5 데이터 셋\n",
    "kk_1516 = kk[(kk['회계년도'] <= '2016/12') & (kk['회계년도'] >= '2015/12')]\n",
    "kk_11141719 = kk[(kk['회계년도'] <= '2019/12') & (kk['회계년도'] >= '2017/12') | (kk['회계년도'] >= '2011/12') & (kk['회계년도'] <= '2014/12')]\n",
    "# 교차검증 6 데이터 셋\n",
    "kk_1617 = kk[(kk['회계년도'] <= '2017/12') & (kk['회계년도'] >= '2016/12')]\n",
    "kk_11151819 = kk[(kk['회계년도'] <= '2019/12') & (kk['회계년도'] >= '2018/12') | (kk['회계년도'] >= '2011/12') & (kk['회계년도'] <= '2015/12')]\n",
    "# 교차검증 7 데이터 셋\n",
    "kk_1718 = kk[(kk['회계년도'] <= '2018/12') & (kk['회계년도'] >= '2017/12')]\n",
    "kk_111619 = kk[(kk['회계년도'] == '2019/12') | (kk['회계년도'] >= '2011/12') & (kk['회계년도'] <= '2016/12')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2232\n",
       "1      17\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk_1718['label'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 코스닥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 교차검증 1 데이터 셋\n",
    "# kosdaq_1112 = kosdaq[(kosdaq['회계년도'] <= '2012/12') & (kosdaq['회계년도'] >= '2011/12')]\n",
    "# kosdaq_1319 = kosdaq[(kosdaq['회계년도'] <= '2019/12') & (kosdaq['회계년도'] >= '2013/12')]\n",
    "# # 교차검증 2 데이터 셋\n",
    "# kosdaq_1213 = kosdaq[(kosdaq['회계년도'] <= '2013/12') & (kosdaq['회계년도'] >= '2012/12')]\n",
    "# kosdaq_111419 = kosdaq[(kosdaq['회계년도'] <= '2019/12') & (kosdaq['회계년도'] >= '2014/12') | (kosdaq['회계년도'] == '2011/12')]\n",
    "# # 교차검증 3 데이터 셋\n",
    "# kosdaq_1314 = kosdaq[(kosdaq['회계년도'] <= '2014/12') & (kosdaq['회계년도'] >= '2013/12')]\n",
    "# kosdaq_11121519 = kosdaq[(kosdaq['회계년도'] <= '2019/12') & (kosdaq['회계년도'] >= '2015/12') | (kosdaq['회계년도'] >= '2011/12') & (kosdaq['회계년도'] <= '2012/12')]\n",
    "# # 교차검증 4 데이터 셋\n",
    "# kosdaq_1415 = kosdaq[(kosdaq['회계년도'] <= '2015/12') & (kosdaq['회계년도'] >= '2014/12')]\n",
    "# kosdaq_11131619 = kosdaq[(kosdaq['회계년도'] <= '2019/12') & (kosdaq['회계년도'] >= '2016/12') | (kosdaq['회계년도'] >= '2011/12') & (kosdaq['회계년도'] <= '2013/12')]\n",
    "# # 교차검증 5 데이터 셋\n",
    "# kosdaq_1516 = kosdaq[(kosdaq['회계년도'] <= '2016/12') & (kosdaq['회계년도'] >= '2015/12')]\n",
    "# kosdaq_11141719 = kosdaq[(kosdaq['회계년도'] <= '2019/12') & (kosdaq['회계년도'] >= '2017/12') | (kosdaq['회계년도'] >= '2011/12') & (kosdaq['회계년도'] <= '2014/12')]\n",
    "# # 교차검증 6 데이터 셋\n",
    "# kosdaq_1617 = kosdaq[(kosdaq['회계년도'] <= '2017/12') & (kosdaq['회계년도'] >= '2016/12')]\n",
    "# kosdaq_11151819 = kosdaq[(kosdaq['회계년도'] <= '2019/12') & (kosdaq['회계년도'] >= '2018/12') | (kosdaq['회계년도'] >= '2011/12') & (kosdaq['회계년도'] <= '2015/12')]\n",
    "# # 교차검증 7 데이터 셋\n",
    "# kosdaq_1718 = kosdaq[(kosdaq['회계년도'] <= '2018/12') & (kosdaq['회계년도'] >= '2017/12')]\n",
    "# kosdaq_111619 = kosdaq[(kosdaq['회계년도'] == '2019/12') | (kosdaq['회계년도'] >= '2011/12') & (kosdaq['회계년도'] <= '2016/12')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>회계년도</th>\n",
       "      <th>총자본증가율</th>\n",
       "      <th>유형자산증가율</th>\n",
       "      <th>유동자산증가율</th>\n",
       "      <th>비유동자산증가율</th>\n",
       "      <th>재고자산증가율</th>\n",
       "      <th>자기자본증가율</th>\n",
       "      <th>매출액증가율</th>\n",
       "      <th>매출총이익증가율</th>\n",
       "      <th>당기순이익증가율</th>\n",
       "      <th>...</th>\n",
       "      <th>현금및현금성자산의증가</th>\n",
       "      <th>경영기간</th>\n",
       "      <th>상장기간</th>\n",
       "      <th>label</th>\n",
       "      <th>산업분류</th>\n",
       "      <th>기업생애주기_Shake-Out</th>\n",
       "      <th>기업생애주기_도입기</th>\n",
       "      <th>기업생애주기_성숙기</th>\n",
       "      <th>기업생애주기_성장기</th>\n",
       "      <th>기업생애주기_쇠퇴기</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011/12</td>\n",
       "      <td>1.975650</td>\n",
       "      <td>-5.902879</td>\n",
       "      <td>17.636684</td>\n",
       "      <td>-12.887724</td>\n",
       "      <td>-1.437298</td>\n",
       "      <td>-2.015757</td>\n",
       "      <td>56.405286</td>\n",
       "      <td>137.025215</td>\n",
       "      <td>78.286537</td>\n",
       "      <td>...</td>\n",
       "      <td>-1295.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012/12</td>\n",
       "      <td>109.148508</td>\n",
       "      <td>-4.130614</td>\n",
       "      <td>207.079069</td>\n",
       "      <td>-16.424273</td>\n",
       "      <td>7.728764</td>\n",
       "      <td>75.174670</td>\n",
       "      <td>-8.432853</td>\n",
       "      <td>-37.961217</td>\n",
       "      <td>-341.644562</td>\n",
       "      <td>...</td>\n",
       "      <td>3522.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2011/12</td>\n",
       "      <td>12.783346</td>\n",
       "      <td>27.822222</td>\n",
       "      <td>3.829865</td>\n",
       "      <td>30.736804</td>\n",
       "      <td>27.477802</td>\n",
       "      <td>-7.918632</td>\n",
       "      <td>21.630551</td>\n",
       "      <td>36.474359</td>\n",
       "      <td>-193.872549</td>\n",
       "      <td>...</td>\n",
       "      <td>-1321.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012/12</td>\n",
       "      <td>-16.574436</td>\n",
       "      <td>-26.240148</td>\n",
       "      <td>-33.367569</td>\n",
       "      <td>10.168699</td>\n",
       "      <td>-8.810241</td>\n",
       "      <td>1.564491</td>\n",
       "      <td>4.853878</td>\n",
       "      <td>5.220425</td>\n",
       "      <td>92.514595</td>\n",
       "      <td>...</td>\n",
       "      <td>911.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2011/12</td>\n",
       "      <td>22.758542</td>\n",
       "      <td>11.463942</td>\n",
       "      <td>23.694934</td>\n",
       "      <td>22.016892</td>\n",
       "      <td>-54.838710</td>\n",
       "      <td>30.731209</td>\n",
       "      <td>30.071634</td>\n",
       "      <td>25.350919</td>\n",
       "      <td>25.874753</td>\n",
       "      <td>...</td>\n",
       "      <td>2231.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11516</th>\n",
       "      <td>2012/12</td>\n",
       "      <td>14.596670</td>\n",
       "      <td>26.034978</td>\n",
       "      <td>11.606015</td>\n",
       "      <td>21.244369</td>\n",
       "      <td>8.694872</td>\n",
       "      <td>18.330311</td>\n",
       "      <td>17.588384</td>\n",
       "      <td>13.057595</td>\n",
       "      <td>7.981221</td>\n",
       "      <td>...</td>\n",
       "      <td>4537.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11534</th>\n",
       "      <td>2011/12</td>\n",
       "      <td>35.071544</td>\n",
       "      <td>27.830619</td>\n",
       "      <td>38.252846</td>\n",
       "      <td>29.382820</td>\n",
       "      <td>17.697084</td>\n",
       "      <td>37.531486</td>\n",
       "      <td>58.705540</td>\n",
       "      <td>73.252321</td>\n",
       "      <td>6.774194</td>\n",
       "      <td>...</td>\n",
       "      <td>1933.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11535</th>\n",
       "      <td>2012/12</td>\n",
       "      <td>-8.497146</td>\n",
       "      <td>-1.253695</td>\n",
       "      <td>-13.744924</td>\n",
       "      <td>1.537542</td>\n",
       "      <td>-5.929579</td>\n",
       "      <td>-2.551893</td>\n",
       "      <td>-38.142627</td>\n",
       "      <td>-49.680826</td>\n",
       "      <td>-487.160121</td>\n",
       "      <td>...</td>\n",
       "      <td>-1056.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11556</th>\n",
       "      <td>2011/12</td>\n",
       "      <td>-1.973172</td>\n",
       "      <td>-5.854894</td>\n",
       "      <td>-5.497614</td>\n",
       "      <td>-0.978158</td>\n",
       "      <td>-24.431818</td>\n",
       "      <td>2.087027</td>\n",
       "      <td>8.116816</td>\n",
       "      <td>8.881911</td>\n",
       "      <td>13.451631</td>\n",
       "      <td>...</td>\n",
       "      <td>514.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11557</th>\n",
       "      <td>2012/12</td>\n",
       "      <td>-1.142093</td>\n",
       "      <td>-0.522513</td>\n",
       "      <td>-2.593840</td>\n",
       "      <td>-0.750945</td>\n",
       "      <td>13.283208</td>\n",
       "      <td>1.414476</td>\n",
       "      <td>4.385881</td>\n",
       "      <td>-13.224843</td>\n",
       "      <td>-27.396569</td>\n",
       "      <td>...</td>\n",
       "      <td>-267.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1645 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          회계년도      총자본증가율    유형자산증가율     유동자산증가율   비유동자산증가율    재고자산증가율  \\\n",
       "0      2011/12    1.975650  -5.902879   17.636684 -12.887724  -1.437298   \n",
       "1      2012/12  109.148508  -4.130614  207.079069 -16.424273   7.728764   \n",
       "11     2011/12   12.783346  27.822222    3.829865  30.736804  27.477802   \n",
       "12     2012/12  -16.574436 -26.240148  -33.367569  10.168699  -8.810241   \n",
       "22     2011/12   22.758542  11.463942   23.694934  22.016892 -54.838710   \n",
       "...        ...         ...        ...         ...        ...        ...   \n",
       "11516  2012/12   14.596670  26.034978   11.606015  21.244369   8.694872   \n",
       "11534  2011/12   35.071544  27.830619   38.252846  29.382820  17.697084   \n",
       "11535  2012/12   -8.497146  -1.253695  -13.744924   1.537542  -5.929579   \n",
       "11556  2011/12   -1.973172  -5.854894   -5.497614  -0.978158 -24.431818   \n",
       "11557  2012/12   -1.142093  -0.522513   -2.593840  -0.750945  13.283208   \n",
       "\n",
       "         자기자본증가율     매출액증가율    매출총이익증가율    당기순이익증가율  ...  현금및현금성자산의증가  경영기간  \\\n",
       "0      -2.015757  56.405286  137.025215   78.286537  ...      -1295.0  10.0   \n",
       "1      75.174670  -8.432853  -37.961217 -341.644562  ...       3522.0  11.0   \n",
       "11     -7.918632  21.630551   36.474359 -193.872549  ...      -1321.0  34.0   \n",
       "12      1.564491   4.853878    5.220425   92.514595  ...        911.0  35.0   \n",
       "22     30.731209  30.071634   25.350919   25.874753  ...       2231.0  12.0   \n",
       "...          ...        ...         ...         ...  ...          ...   ...   \n",
       "11516  18.330311  17.588384   13.057595    7.981221  ...       4537.0  32.0   \n",
       "11534  37.531486  58.705540   73.252321    6.774194  ...       1933.0  13.0   \n",
       "11535  -2.551893 -38.142627  -49.680826 -487.160121  ...      -1056.0  14.0   \n",
       "11556   2.087027   8.116816    8.881911   13.451631  ...        514.0  45.0   \n",
       "11557   1.414476   4.385881  -13.224843  -27.396569  ...       -267.0  46.0   \n",
       "\n",
       "       상장기간  label  산업분류  기업생애주기_Shake-Out  기업생애주기_도입기  기업생애주기_성숙기  \\\n",
       "0      11.0      0     1                 0           1           0   \n",
       "1      12.0      0     1                 0           1           0   \n",
       "11     10.0      0     0                 0           0           0   \n",
       "12     11.0      0     0                 0           0           0   \n",
       "22      7.0      0     0                 0           0           0   \n",
       "...     ...    ...   ...               ...         ...         ...   \n",
       "11516  11.0      0     1                 0           0           0   \n",
       "11534   6.0      0     1                 0           1           0   \n",
       "11535   7.0      0     1                 0           1           0   \n",
       "11556  18.0      0     0                 1           0           0   \n",
       "11557  19.0      0     0                 1           0           0   \n",
       "\n",
       "       기업생애주기_성장기  기업생애주기_쇠퇴기  \n",
       "0               0           0  \n",
       "1               0           0  \n",
       "11              1           0  \n",
       "12              1           0  \n",
       "22              1           0  \n",
       "...           ...         ...  \n",
       "11516           1           0  \n",
       "11534           0           0  \n",
       "11535           0           0  \n",
       "11556           0           0  \n",
       "11557           0           0  \n",
       "\n",
       "[1645 rows x 68 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk[(kk['회계년도'] <= '2012/12') & (kk['회계년도'] >= '2011/12')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7150\n",
       "1      73\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kk[(kk['회계년도'] <= '2019/12') & (kk['회계년도'] >= '2013/12')]['label'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 검증 함수 만들기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1번 데이터 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model1(Data):\n",
    "\n",
    "    train = Data[(Data['회계년도'] <= '2019/12') & (Data['회계년도'] >= '2013/12')].reset_index(drop=True)\n",
    "    test = Data[(Data['회계년도'] <= '2012/12') & (Data['회계년도'] >= '2011/12')].reset_index(drop=True)\n",
    "\n",
    "    ## Train Scaling 전 Data 분리하기 ##\n",
    "\n",
    "    X_train = train.drop(columns=['label', '산업분류', '기업생애주기_Shake-Out',\n",
    "       '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도'], axis=1)\n",
    "    X_train_concat = train[['산업분류', '기업생애주기_Shake-Out',\n",
    "        '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도']]\n",
    "    y_train = train[['label']]\n",
    "    X_test = test.drop(columns=['label', '산업분류', '기업생애주기_Shake-Out',\n",
    "       '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도'], axis=1)\n",
    "    X_test_concat = test[['산업분류', '기업생애주기_Shake-Out',\n",
    "        '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도']]\n",
    "    y_test = test[['label']]\n",
    "\n",
    "\n",
    "    ## Scaling##\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    # StandardScaler() Scaler객체 생성.\n",
    "    scaler = StandardScaler()\n",
    "    # 학습 데이터에 대해서 fit(), transform() 수행.\n",
    "    scaler.fit(X_train)\n",
    "    train_scaled_SS = scaler.transform(X_train)\n",
    "    # transform()시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
    "    X_train_SS = pd.DataFrame(data = train_scaled_SS, columns=X_train.columns)\n",
    "\n",
    "    # 테스트 데이터에서는 다시 fit(), transform()이나 fit_transform()을 수행하지 않고 transform만 수행.\n",
    "    test_scaled_MM = scaler.transform(X_test)\n",
    "    # transform()시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
    "    X_test_SS = pd.DataFrame(data = test_scaled_MM, columns=X_test.columns)\n",
    "\n",
    "\n",
    "    X_train_SS = pd.concat([X_train_SS,X_train_concat,y_train], axis=1)\n",
    "    X_test_SS = pd.concat([X_test_SS,X_test_concat, y_test], axis=1)\n",
    "\n",
    "    trian_test_df = pd.concat([X_train_SS, X_test_SS], axis=0)\n",
    "    trian_test_df.reset_index(drop=True, inplace=True)      \n",
    "\n",
    "    df_2011 = trian_test_df[trian_test_df['회계년도'] == '2011/12']\n",
    "    df_2012 = trian_test_df[trian_test_df['회계년도'] == '2012/12']\n",
    "    df_2013 = trian_test_df[trian_test_df['회계년도'] == '2013/12']\n",
    "    df_2014 = trian_test_df[trian_test_df['회계년도'] == '2014/12']\n",
    "    df_2015 = trian_test_df[trian_test_df['회계년도'] == '2015/12']\n",
    "    df_2016 = trian_test_df[trian_test_df['회계년도'] == '2016/12']\n",
    "    df_2017 = trian_test_df[trian_test_df['회계년도'] == '2017/12']\n",
    "    df_2018 = trian_test_df[trian_test_df['회계년도'] == '2018/12']\n",
    "    df_2019 = trian_test_df[trian_test_df['회계년도'] == '2019/12']\n",
    "\n",
    "    df_X_2011 = df_2011.drop(columns='label', axis=1)\n",
    "    df_y_2011 = df_2011[['label']]\n",
    "    df_X_2012 = df_2012.drop(columns='label', axis=1)\n",
    "    df_y_2012 = df_2012[['label']]\n",
    "    df_X_2013 = df_2013.drop(columns='label', axis=1)\n",
    "    df_y_2013 = df_2013[['label']]\n",
    "    df_X_2014 = df_2014.drop(columns='label', axis=1)\n",
    "    df_y_2014 = df_2014[['label']]\n",
    "    df_X_2015 = df_2015.drop(columns='label', axis=1)\n",
    "    df_y_2015 = df_2015[['label']]\n",
    "    df_X_2016 = df_2016.drop(columns='label', axis=1)\n",
    "    df_y_2016 = df_2016[['label']]\n",
    "    df_X_2017 = df_2017.drop(columns='label', axis=1)\n",
    "    df_y_2017 = df_2017[['label']]\n",
    "    df_X_2018 = df_2018.drop(columns='label', axis=1)\n",
    "    df_y_2018 = df_2018[['label']]\n",
    "    df_X_2019 = df_2019.drop(columns='label', axis=1)\n",
    "    df_y_2019 = df_2019[['label']]\n",
    "    \n",
    "\n",
    "    ## UnderSampler ##\n",
    "\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "    X_samp_11, y_samp_11 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2011, df_y_2011)\n",
    "    X_samp_12, y_samp_12 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2012, df_y_2012)\n",
    "    X_samp_13, y_samp_13 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2013, df_y_2013)\n",
    "    X_samp_14, y_samp_14 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2014, df_y_2014)\n",
    "    X_samp_15, y_samp_15 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2015, df_y_2015)\n",
    "    X_samp_16, y_samp_16 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2016, df_y_2016)\n",
    "    X_samp_17, y_samp_17 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2017, df_y_2017)\n",
    "    X_samp_18, y_samp_18 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2018, df_y_2018)\n",
    "    X_samp_19, y_samp_19 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2019, df_y_2019)\n",
    "\n",
    "    X_samp = pd.concat([X_samp_11, X_samp_12, X_samp_13, X_samp_14, X_samp_15, X_samp_16, X_samp_17, X_samp_18, X_samp_19], axis=0)\n",
    "    y_samp = pd.concat([y_samp_11, y_samp_12, y_samp_13, y_samp_14, y_samp_15, y_samp_16, y_samp_17, y_samp_18, y_samp_19], axis=0)\n",
    "\n",
    "    trian_test_samp_df = pd.concat([X_samp, y_samp], axis=1)\n",
    "\n",
    "    # 교차검증 1 데이터 셋\n",
    "    X_samp_train = trian_test_samp_df[(trian_test_samp_df['회계년도'] <= '2019/12') & (trian_test_samp_df['회계년도'] >= '2013/12')]\n",
    "    X_samp_test = trian_test_samp_df[(trian_test_samp_df['회계년도'] <= '2012/12') & (trian_test_samp_df['회계년도'] >= '2011/12')]\n",
    "\n",
    "    X_samp_train_1 = X_samp_train.drop(columns=['label', '회계년도'], axis=1)\n",
    "    y_samp_train_1 = X_samp_train[['label']]\n",
    "\n",
    "    X_samp_test_1 = X_samp_test.drop(columns=['label', '회계년도'], axis=1)\n",
    "    y_samp_test_1 = X_samp_test[['label']]\n",
    "\n",
    "    X_samp_train_1.reset_index(drop=True, inplace=True)\n",
    "    X_samp_test_1.reset_index(drop=True, inplace=True)\n",
    "    y_samp_train_1.reset_index(drop=True, inplace=True)\n",
    "    y_samp_test_1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "    X_samp_2, y_samp_2 = BorderlineSMOTE(random_state=0,sampling_strategy=1).fit_resample(X_samp_train_1, y_samp_train_1)\n",
    "\n",
    "    train_df = pd.concat([X_samp_2, y_samp_2], axis=1)\n",
    "    test_df = pd.concat([X_samp_test_1, y_samp_test_1], axis=1)\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    365\n",
       "1    365\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1(kk)[0]['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    260\n",
       "1     52\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1(kk)[1]['label'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2번 데이터 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2(Data):\n",
    "\n",
    "    train = Data[(Data['회계년도'] <= '2019/12') & (Data['회계년도'] >= '2014/12') | (Data['회계년도'] == '2011/12')].reset_index(drop=True)\n",
    "    test = Data[(Data['회계년도'] <= '2013/12') & (Data['회계년도'] >= '2012/12')].reset_index(drop=True)\n",
    "    ## Train Scaling 전 Data 분리하기 ##\n",
    "\n",
    "    X_train = train.drop(columns=['label', '산업분류', '기업생애주기_Shake-Out',\n",
    "       '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도'], axis=1)\n",
    "    X_train_concat = train[['산업분류', '기업생애주기_Shake-Out',\n",
    "        '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도']]\n",
    "    y_train = train[['label']]\n",
    "    X_test = test.drop(columns=['label', '산업분류', '기업생애주기_Shake-Out',\n",
    "       '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도'], axis=1)\n",
    "    X_test_concat = test[['산업분류', '기업생애주기_Shake-Out',\n",
    "        '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도']]\n",
    "    y_test = test[['label']]\n",
    "\n",
    "\n",
    "    ## Scaling##\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    # StandardScaler() Scaler객체 생성.\n",
    "    scaler = StandardScaler()\n",
    "    # 학습 데이터에 대해서 fit(), transform() 수행.\n",
    "    scaler.fit(X_train)\n",
    "    train_scaled_SS = scaler.transform(X_train)\n",
    "    # transform()시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
    "    X_train_SS = pd.DataFrame(data = train_scaled_SS, columns=X_train.columns)\n",
    "\n",
    "    # 테스트 데이터에서는 다시 fit(), transform()이나 fit_transform()을 수행하지 않고 transform만 수행.\n",
    "    test_scaled_MM = scaler.transform(X_test)\n",
    "    # transform()시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
    "    X_test_SS = pd.DataFrame(data = test_scaled_MM, columns=X_test.columns)\n",
    "\n",
    "\n",
    "    X_train_SS = pd.concat([X_train_SS,X_train_concat,y_train], axis=1)\n",
    "    X_test_SS = pd.concat([X_test_SS,X_test_concat, y_test], axis=1)\n",
    "\n",
    "    trian_test_df = pd.concat([X_train_SS, X_test_SS], axis=0)\n",
    "    trian_test_df.reset_index(drop=True, inplace=True)      \n",
    "\n",
    "    df_2011 = trian_test_df[trian_test_df['회계년도'] == '2011/12']\n",
    "    df_2012 = trian_test_df[trian_test_df['회계년도'] == '2012/12']\n",
    "    df_2013 = trian_test_df[trian_test_df['회계년도'] == '2013/12']\n",
    "    df_2014 = trian_test_df[trian_test_df['회계년도'] == '2014/12']\n",
    "    df_2015 = trian_test_df[trian_test_df['회계년도'] == '2015/12']\n",
    "    df_2016 = trian_test_df[trian_test_df['회계년도'] == '2016/12']\n",
    "    df_2017 = trian_test_df[trian_test_df['회계년도'] == '2017/12']\n",
    "    df_2018 = trian_test_df[trian_test_df['회계년도'] == '2018/12']\n",
    "    df_2019 = trian_test_df[trian_test_df['회계년도'] == '2019/12']\n",
    "\n",
    "    df_X_2011 = df_2011.drop(columns='label', axis=1)\n",
    "    df_y_2011 = df_2011[['label']]\n",
    "    df_X_2012 = df_2012.drop(columns='label', axis=1)\n",
    "    df_y_2012 = df_2012[['label']]\n",
    "    df_X_2013 = df_2013.drop(columns='label', axis=1)\n",
    "    df_y_2013 = df_2013[['label']]\n",
    "    df_X_2014 = df_2014.drop(columns='label', axis=1)\n",
    "    df_y_2014 = df_2014[['label']]\n",
    "    df_X_2015 = df_2015.drop(columns='label', axis=1)\n",
    "    df_y_2015 = df_2015[['label']]\n",
    "    df_X_2016 = df_2016.drop(columns='label', axis=1)\n",
    "    df_y_2016 = df_2016[['label']]\n",
    "    df_X_2017 = df_2017.drop(columns='label', axis=1)\n",
    "    df_y_2017 = df_2017[['label']]\n",
    "    df_X_2018 = df_2018.drop(columns='label', axis=1)\n",
    "    df_y_2018 = df_2018[['label']]\n",
    "    df_X_2019 = df_2019.drop(columns='label', axis=1)\n",
    "    df_y_2019 = df_2019[['label']]\n",
    "    \n",
    "\n",
    "    ## UnderSampler ##\n",
    "\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "    X_samp_11, y_samp_11 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2011, df_y_2011)\n",
    "    X_samp_12, y_samp_12 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2012, df_y_2012)\n",
    "    X_samp_13, y_samp_13 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2013, df_y_2013)\n",
    "    X_samp_14, y_samp_14 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2014, df_y_2014)\n",
    "    X_samp_15, y_samp_15 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2015, df_y_2015)\n",
    "    X_samp_16, y_samp_16 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2016, df_y_2016)\n",
    "    X_samp_17, y_samp_17 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2017, df_y_2017)\n",
    "    X_samp_18, y_samp_18 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2018, df_y_2018)\n",
    "    X_samp_19, y_samp_19 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2019, df_y_2019)\n",
    "\n",
    "    X_samp = pd.concat([X_samp_11, X_samp_12, X_samp_13, X_samp_14, X_samp_15, X_samp_16, X_samp_17, X_samp_18, X_samp_19], axis=0)\n",
    "    y_samp = pd.concat([y_samp_11, y_samp_12, y_samp_13, y_samp_14, y_samp_15, y_samp_16, y_samp_17, y_samp_18, y_samp_19], axis=0)\n",
    "\n",
    "    a = pd.concat([X_samp, y_samp], axis=1)\n",
    "\n",
    "    # 교차검증 2 데이터 셋\n",
    "    X_samp_train = a[(a['회계년도'] <= '2019/12') & (a['회계년도'] >= '2014/12') | (a['회계년도'] == '2011/12')]\n",
    "    X_samp_test = a[(a['회계년도'] <= '2013/12') & (a['회계년도'] >= '2012/12')]\n",
    "\n",
    "    X_samp_train_1 = X_samp_train.drop(columns=['label', '회계년도'], axis=1)\n",
    "    y_samp_train_1 = X_samp_train[['label']]\n",
    "\n",
    "    X_samp_test_1 = X_samp_test.drop(columns=['label', '회계년도'], axis=1)\n",
    "    y_samp_test_1 = X_samp_test[['label']]\n",
    "\n",
    "    X_samp_train_1.reset_index(drop=True, inplace=True)\n",
    "    X_samp_test_1.reset_index(drop=True, inplace=True)\n",
    "    y_samp_train_1.reset_index(drop=True, inplace=True)\n",
    "    y_samp_test_1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "    X_samp_2, y_samp_2 = BorderlineSMOTE(random_state=0,sampling_strategy=1).fit_resample(X_samp_train_1, y_samp_train_1)\n",
    "\n",
    "    train_df = pd.concat([X_samp_2, y_samp_2], axis=1)\n",
    "    test_df = pd.concat([X_samp_test_1, y_samp_test_1], axis=1)\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    450\n",
       "1    450\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2(kk)[0]['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    175\n",
       "1     35\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2(kk)[1]['label'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3번 데이터 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model3(Data):\n",
    "\n",
    "    train = Data[(Data['회계년도'] <= '2019/12') & (Data['회계년도'] >= '2015/12') | (Data['회계년도'] >= '2011/12') & (Data['회계년도'] <= '2012/12')].reset_index(drop=True)\n",
    "    test = Data[(Data['회계년도'] <= '2014/12') & (Data['회계년도'] >= '2013/12')].reset_index(drop=True)\n",
    "\n",
    "    X_train = train.drop(columns=['label', '산업분류', '기업생애주기_Shake-Out',\n",
    "       '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도'], axis=1)\n",
    "    X_train_concat = train[['산업분류', '기업생애주기_Shake-Out',\n",
    "        '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도']]\n",
    "    y_train = train[['label']]\n",
    "    X_test = test.drop(columns=['label', '산업분류', '기업생애주기_Shake-Out',\n",
    "       '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도'], axis=1)\n",
    "    X_test_concat = test[['산업분류', '기업생애주기_Shake-Out',\n",
    "        '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도']]\n",
    "    y_test = test[['label']]\n",
    "\n",
    "\n",
    "    ## Scaling##\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    # StandardScaler() Scaler객체 생성.\n",
    "    scaler = StandardScaler()\n",
    "    # 학습 데이터에 대해서 fit(), transform() 수행.\n",
    "    scaler.fit(X_train)\n",
    "    train_scaled_SS = scaler.transform(X_train)\n",
    "    # transform()시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
    "    X_train_SS = pd.DataFrame(data = train_scaled_SS, columns=X_train.columns)\n",
    "\n",
    "    # 테스트 데이터에서는 다시 fit(), transform()이나 fit_transform()을 수행하지 않고 transform만 수행.\n",
    "    test_scaled_MM = scaler.transform(X_test)\n",
    "    # transform()시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
    "    X_test_SS = pd.DataFrame(data = test_scaled_MM, columns=X_test.columns)\n",
    "\n",
    "\n",
    "    X_train_SS = pd.concat([X_train_SS,X_train_concat,y_train], axis=1)\n",
    "    X_test_SS = pd.concat([X_test_SS,X_test_concat, y_test], axis=1)\n",
    "\n",
    "    trian_test_df = pd.concat([X_train_SS, X_test_SS], axis=0)\n",
    "    trian_test_df.reset_index(drop=True, inplace=True)      \n",
    "\n",
    "    df_2011 = trian_test_df[trian_test_df['회계년도'] == '2011/12']\n",
    "    df_2012 = trian_test_df[trian_test_df['회계년도'] == '2012/12']\n",
    "    df_2013 = trian_test_df[trian_test_df['회계년도'] == '2013/12']\n",
    "    df_2014 = trian_test_df[trian_test_df['회계년도'] == '2014/12']\n",
    "    df_2015 = trian_test_df[trian_test_df['회계년도'] == '2015/12']\n",
    "    df_2016 = trian_test_df[trian_test_df['회계년도'] == '2016/12']\n",
    "    df_2017 = trian_test_df[trian_test_df['회계년도'] == '2017/12']\n",
    "    df_2018 = trian_test_df[trian_test_df['회계년도'] == '2018/12']\n",
    "    df_2019 = trian_test_df[trian_test_df['회계년도'] == '2019/12']\n",
    "\n",
    "    df_X_2011 = df_2011.drop(columns='label', axis=1)\n",
    "    df_y_2011 = df_2011[['label']]\n",
    "    df_X_2012 = df_2012.drop(columns='label', axis=1)\n",
    "    df_y_2012 = df_2012[['label']]\n",
    "    df_X_2013 = df_2013.drop(columns='label', axis=1)\n",
    "    df_y_2013 = df_2013[['label']]\n",
    "    df_X_2014 = df_2014.drop(columns='label', axis=1)\n",
    "    df_y_2014 = df_2014[['label']]\n",
    "    df_X_2015 = df_2015.drop(columns='label', axis=1)\n",
    "    df_y_2015 = df_2015[['label']]\n",
    "    df_X_2016 = df_2016.drop(columns='label', axis=1)\n",
    "    df_y_2016 = df_2016[['label']]\n",
    "    df_X_2017 = df_2017.drop(columns='label', axis=1)\n",
    "    df_y_2017 = df_2017[['label']]\n",
    "    df_X_2018 = df_2018.drop(columns='label', axis=1)\n",
    "    df_y_2018 = df_2018[['label']]\n",
    "    df_X_2019 = df_2019.drop(columns='label', axis=1)\n",
    "    df_y_2019 = df_2019[['label']]\n",
    "    \n",
    "\n",
    "    ## UnderSampler ##\n",
    "\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "    X_samp_11, y_samp_11 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2011, df_y_2011)\n",
    "    X_samp_12, y_samp_12 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2012, df_y_2012)\n",
    "    X_samp_13, y_samp_13 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2013, df_y_2013)\n",
    "    X_samp_14, y_samp_14 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2014, df_y_2014)\n",
    "    X_samp_15, y_samp_15 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2015, df_y_2015)\n",
    "    X_samp_16, y_samp_16 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2016, df_y_2016)\n",
    "    X_samp_17, y_samp_17 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2017, df_y_2017)\n",
    "    X_samp_18, y_samp_18 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2018, df_y_2018)\n",
    "    X_samp_19, y_samp_19 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2019, df_y_2019)\n",
    "\n",
    "    X_samp = pd.concat([X_samp_11, X_samp_12, X_samp_13, X_samp_14, X_samp_15, X_samp_16, X_samp_17, X_samp_18, X_samp_19], axis=0)\n",
    "    y_samp = pd.concat([y_samp_11, y_samp_12, y_samp_13, y_samp_14, y_samp_15, y_samp_16, y_samp_17, y_samp_18, y_samp_19], axis=0)\n",
    "\n",
    "    a = pd.concat([X_samp, y_samp], axis=1)\n",
    "\n",
    "    # 교차검증 3 데이터 셋\n",
    "    X_samp_train = a[(a['회계년도'] <= '2019/12') & (a['회계년도'] >= '2015/12') | (a['회계년도'] >= '2011/12') & (a['회계년도'] <= '2012/12')]\n",
    "    X_samp_test = a[(a['회계년도'] <= '2014/12') & (a['회계년도'] >= '2013/12')]\n",
    "\n",
    "    X_samp_train_1 = X_samp_train.drop(columns=['label', '회계년도'], axis=1)\n",
    "    y_samp_train_1 = X_samp_train[['label']]\n",
    "\n",
    "    X_samp_test_1 = X_samp_test.drop(columns=['label', '회계년도'], axis=1)\n",
    "    y_samp_test_1 = X_samp_test[['label']]\n",
    "\n",
    "    X_samp_train_1.reset_index(drop=True, inplace=True)\n",
    "    X_samp_test_1.reset_index(drop=True, inplace=True)\n",
    "    y_samp_train_1.reset_index(drop=True, inplace=True)\n",
    "    y_samp_test_1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "    X_samp_2, y_samp_2 = BorderlineSMOTE(random_state=0,sampling_strategy=1).fit_resample(X_samp_train_1, y_samp_train_1)\n",
    "\n",
    "    train_df = pd.concat([X_samp_2, y_samp_2], axis=1)\n",
    "    test_df = pd.concat([X_samp_test_1, y_samp_test_1], axis=1)\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    490\n",
       "1    490\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3(kk)[0]['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    135\n",
       "1     27\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3(kk)[1]['label'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4번 데이터 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model4(Data):\n",
    "\n",
    "    train = Data[(Data['회계년도'] <= '2019/12') & (Data['회계년도'] >= '2016/12') | (Data['회계년도'] >= '2011/12') & (Data['회계년도'] <= '2013/12')].reset_index(drop=True)\n",
    "    test = Data[(Data['회계년도'] <= '2015/12') & (Data['회계년도'] >= '2014/12')].reset_index(drop=True)\n",
    "\n",
    "    X_train = train.drop(columns=['label', '산업분류', '기업생애주기_Shake-Out',\n",
    "       '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도'], axis=1)\n",
    "    X_train_concat = train[['산업분류', '기업생애주기_Shake-Out',\n",
    "        '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도']]\n",
    "    y_train = train[['label']]\n",
    "    X_test = test.drop(columns=['label', '산업분류', '기업생애주기_Shake-Out',\n",
    "       '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도'], axis=1)\n",
    "    X_test_concat = test[['산업분류', '기업생애주기_Shake-Out',\n",
    "        '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도']]\n",
    "    y_test = test[['label']]\n",
    "\n",
    "\n",
    "    ## Scaling##\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    # StandardScaler() Scaler객체 생성.\n",
    "    scaler = StandardScaler()\n",
    "    # 학습 데이터에 대해서 fit(), transform() 수행.\n",
    "    scaler.fit(X_train)\n",
    "    train_scaled_SS = scaler.transform(X_train)\n",
    "    # transform()시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
    "    X_train_SS = pd.DataFrame(data = train_scaled_SS, columns=X_train.columns)\n",
    "\n",
    "    # 테스트 데이터에서는 다시 fit(), transform()이나 fit_transform()을 수행하지 않고 transform만 수행.\n",
    "    test_scaled_MM = scaler.transform(X_test)\n",
    "    # transform()시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
    "    X_test_SS = pd.DataFrame(data = test_scaled_MM, columns=X_test.columns)\n",
    "\n",
    "\n",
    "    X_train_SS = pd.concat([X_train_SS,X_train_concat,y_train], axis=1)\n",
    "    X_test_SS = pd.concat([X_test_SS,X_test_concat, y_test], axis=1)\n",
    "\n",
    "    trian_test_df = pd.concat([X_train_SS, X_test_SS], axis=0)\n",
    "    trian_test_df.reset_index(drop=True, inplace=True)      \n",
    "\n",
    "    df_2011 = trian_test_df[trian_test_df['회계년도'] == '2011/12']\n",
    "    df_2012 = trian_test_df[trian_test_df['회계년도'] == '2012/12']\n",
    "    df_2013 = trian_test_df[trian_test_df['회계년도'] == '2013/12']\n",
    "    df_2014 = trian_test_df[trian_test_df['회계년도'] == '2014/12']\n",
    "    df_2015 = trian_test_df[trian_test_df['회계년도'] == '2015/12']\n",
    "    df_2016 = trian_test_df[trian_test_df['회계년도'] == '2016/12']\n",
    "    df_2017 = trian_test_df[trian_test_df['회계년도'] == '2017/12']\n",
    "    df_2018 = trian_test_df[trian_test_df['회계년도'] == '2018/12']\n",
    "    df_2019 = trian_test_df[trian_test_df['회계년도'] == '2019/12']\n",
    "\n",
    "    df_X_2011 = df_2011.drop(columns='label', axis=1)\n",
    "    df_y_2011 = df_2011[['label']]\n",
    "    df_X_2012 = df_2012.drop(columns='label', axis=1)\n",
    "    df_y_2012 = df_2012[['label']]\n",
    "    df_X_2013 = df_2013.drop(columns='label', axis=1)\n",
    "    df_y_2013 = df_2013[['label']]\n",
    "    df_X_2014 = df_2014.drop(columns='label', axis=1)\n",
    "    df_y_2014 = df_2014[['label']]\n",
    "    df_X_2015 = df_2015.drop(columns='label', axis=1)\n",
    "    df_y_2015 = df_2015[['label']]\n",
    "    df_X_2016 = df_2016.drop(columns='label', axis=1)\n",
    "    df_y_2016 = df_2016[['label']]\n",
    "    df_X_2017 = df_2017.drop(columns='label', axis=1)\n",
    "    df_y_2017 = df_2017[['label']]\n",
    "    df_X_2018 = df_2018.drop(columns='label', axis=1)\n",
    "    df_y_2018 = df_2018[['label']]\n",
    "    df_X_2019 = df_2019.drop(columns='label', axis=1)\n",
    "    df_y_2019 = df_2019[['label']]\n",
    "    \n",
    "\n",
    "    ## UnderSampler ##\n",
    "\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "    X_samp_11, y_samp_11 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2011, df_y_2011)\n",
    "    X_samp_12, y_samp_12 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2012, df_y_2012)\n",
    "    X_samp_13, y_samp_13 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2013, df_y_2013)\n",
    "    X_samp_14, y_samp_14 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2014, df_y_2014)\n",
    "    X_samp_15, y_samp_15 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2015, df_y_2015)\n",
    "    X_samp_16, y_samp_16 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2016, df_y_2016)\n",
    "    X_samp_17, y_samp_17 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2017, df_y_2017)\n",
    "    X_samp_18, y_samp_18 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2018, df_y_2018)\n",
    "    X_samp_19, y_samp_19 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2019, df_y_2019)\n",
    "\n",
    "    X_samp = pd.concat([X_samp_11, X_samp_12, X_samp_13, X_samp_14, X_samp_15, X_samp_16, X_samp_17, X_samp_18, X_samp_19], axis=0)\n",
    "    y_samp = pd.concat([y_samp_11, y_samp_12, y_samp_13, y_samp_14, y_samp_15, y_samp_16, y_samp_17, y_samp_18, y_samp_19], axis=0)\n",
    "\n",
    "    a = pd.concat([X_samp, y_samp], axis=1)\n",
    "\n",
    "    # 교차검증 3 데이터 셋\n",
    "    X_samp_train = a[(a['회계년도'] <= '2019/12') & (a['회계년도'] >= '2016/12') | (a['회계년도'] >= '2011/12') & (a['회계년도'] <= '2013/12')]\n",
    "    X_samp_test = a[(a['회계년도'] <= '2015/12') & (a['회계년도'] >= '2014/12')]\n",
    "\n",
    "    X_samp_train_1 = X_samp_train.drop(columns=['label', '회계년도'], axis=1)\n",
    "    y_samp_train_1 = X_samp_train[['label']]\n",
    "\n",
    "    X_samp_test_1 = X_samp_test.drop(columns=['label', '회계년도'], axis=1)\n",
    "    y_samp_test_1 = X_samp_test[['label']]\n",
    "\n",
    "    X_samp_train_1.reset_index(drop=True, inplace=True)\n",
    "    X_samp_test_1.reset_index(drop=True, inplace=True)\n",
    "    y_samp_train_1.reset_index(drop=True, inplace=True)\n",
    "    y_samp_test_1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "    X_samp_2, y_samp_2 = BorderlineSMOTE(random_state=0,sampling_strategy=1).fit_resample(X_samp_train_1, y_samp_train_1)\n",
    "\n",
    "    train_df = pd.concat([X_samp_2, y_samp_2], axis=1)\n",
    "    test_df = pd.concat([X_samp_test_1, y_samp_test_1], axis=1)\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    510\n",
       "1    510\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4(kk)[0]['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    115\n",
       "1     23\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4(kk)[1]['label'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5번 데이터 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model5(Data):\n",
    "\n",
    "    train = Data[(Data['회계년도'] <= '2019/12') & (Data['회계년도'] >= '2017/12') | (Data['회계년도'] >= '2011/12') & (Data['회계년도'] <= '2014/12')].reset_index(drop=True)\n",
    "    test = Data[(Data['회계년도'] <= '2016/12') & (Data['회계년도'] >= '2015/12')].reset_index(drop=True)\n",
    "\n",
    "    X_train = train.drop(columns=['label', '산업분류', '기업생애주기_Shake-Out',\n",
    "       '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도'], axis=1)\n",
    "    X_train_concat = train[['산업분류', '기업생애주기_Shake-Out',\n",
    "        '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도']]\n",
    "    y_train = train[['label']]\n",
    "    X_test = test.drop(columns=['label', '산업분류', '기업생애주기_Shake-Out',\n",
    "       '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도'], axis=1)\n",
    "    X_test_concat = test[['산업분류', '기업생애주기_Shake-Out',\n",
    "        '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도']]\n",
    "    y_test = test[['label']]\n",
    "\n",
    "\n",
    "    ## Scaling##\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    # StandardScaler() Scaler객체 생성.\n",
    "    scaler = StandardScaler()\n",
    "    # 학습 데이터에 대해서 fit(), transform() 수행.\n",
    "    scaler.fit(X_train)\n",
    "    train_scaled_SS = scaler.transform(X_train)\n",
    "    # transform()시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
    "    X_train_SS = pd.DataFrame(data = train_scaled_SS, columns=X_train.columns)\n",
    "\n",
    "    # 테스트 데이터에서는 다시 fit(), transform()이나 fit_transform()을 수행하지 않고 transform만 수행.\n",
    "    test_scaled_MM = scaler.transform(X_test)\n",
    "    # transform()시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
    "    X_test_SS = pd.DataFrame(data = test_scaled_MM, columns=X_test.columns)\n",
    "\n",
    "\n",
    "    X_train_SS = pd.concat([X_train_SS,X_train_concat,y_train], axis=1)\n",
    "    X_test_SS = pd.concat([X_test_SS,X_test_concat, y_test], axis=1)\n",
    "\n",
    "    trian_test_df = pd.concat([X_train_SS, X_test_SS], axis=0)\n",
    "    trian_test_df.reset_index(drop=True, inplace=True)      \n",
    "\n",
    "    df_2011 = trian_test_df[trian_test_df['회계년도'] == '2011/12']\n",
    "    df_2012 = trian_test_df[trian_test_df['회계년도'] == '2012/12']\n",
    "    df_2013 = trian_test_df[trian_test_df['회계년도'] == '2013/12']\n",
    "    df_2014 = trian_test_df[trian_test_df['회계년도'] == '2014/12']\n",
    "    df_2015 = trian_test_df[trian_test_df['회계년도'] == '2015/12']\n",
    "    df_2016 = trian_test_df[trian_test_df['회계년도'] == '2016/12']\n",
    "    df_2017 = trian_test_df[trian_test_df['회계년도'] == '2017/12']\n",
    "    df_2018 = trian_test_df[trian_test_df['회계년도'] == '2018/12']\n",
    "    df_2019 = trian_test_df[trian_test_df['회계년도'] == '2019/12']\n",
    "\n",
    "    df_X_2011 = df_2011.drop(columns='label', axis=1)\n",
    "    df_y_2011 = df_2011[['label']]\n",
    "    df_X_2012 = df_2012.drop(columns='label', axis=1)\n",
    "    df_y_2012 = df_2012[['label']]\n",
    "    df_X_2013 = df_2013.drop(columns='label', axis=1)\n",
    "    df_y_2013 = df_2013[['label']]\n",
    "    df_X_2014 = df_2014.drop(columns='label', axis=1)\n",
    "    df_y_2014 = df_2014[['label']]\n",
    "    df_X_2015 = df_2015.drop(columns='label', axis=1)\n",
    "    df_y_2015 = df_2015[['label']]\n",
    "    df_X_2016 = df_2016.drop(columns='label', axis=1)\n",
    "    df_y_2016 = df_2016[['label']]\n",
    "    df_X_2017 = df_2017.drop(columns='label', axis=1)\n",
    "    df_y_2017 = df_2017[['label']]\n",
    "    df_X_2018 = df_2018.drop(columns='label', axis=1)\n",
    "    df_y_2018 = df_2018[['label']]\n",
    "    df_X_2019 = df_2019.drop(columns='label', axis=1)\n",
    "    df_y_2019 = df_2019[['label']]\n",
    "    \n",
    "\n",
    "    ## UnderSampler ##\n",
    "\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "    X_samp_11, y_samp_11 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2011, df_y_2011)\n",
    "    X_samp_12, y_samp_12 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2012, df_y_2012)\n",
    "    X_samp_13, y_samp_13 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2013, df_y_2013)\n",
    "    X_samp_14, y_samp_14 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2014, df_y_2014)\n",
    "    X_samp_15, y_samp_15 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2015, df_y_2015)\n",
    "    X_samp_16, y_samp_16 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2016, df_y_2016)\n",
    "    X_samp_17, y_samp_17 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2017, df_y_2017)\n",
    "    X_samp_18, y_samp_18 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2018, df_y_2018)\n",
    "    X_samp_19, y_samp_19 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2019, df_y_2019)\n",
    "\n",
    "    X_samp = pd.concat([X_samp_11, X_samp_12, X_samp_13, X_samp_14, X_samp_15, X_samp_16, X_samp_17, X_samp_18, X_samp_19], axis=0)\n",
    "    y_samp = pd.concat([y_samp_11, y_samp_12, y_samp_13, y_samp_14, y_samp_15, y_samp_16, y_samp_17, y_samp_18, y_samp_19], axis=0)\n",
    "\n",
    "    a = pd.concat([X_samp, y_samp], axis=1)\n",
    "\n",
    "    # 교차검증 3 데이터 셋\n",
    "    X_samp_train = a[(a['회계년도'] <= '2019/12') & (a['회계년도'] >= '2017/12') | (a['회계년도'] >= '2011/12') & (a['회계년도'] <= '2014/12')]\n",
    "    X_samp_test = a[(a['회계년도'] <= '2016/12') & (a['회계년도'] >= '2015/12')]\n",
    "\n",
    "    X_samp_train_1 = X_samp_train.drop(columns=['label', '회계년도'], axis=1)\n",
    "    y_samp_train_1 = X_samp_train[['label']]\n",
    "\n",
    "    X_samp_test_1 = X_samp_test.drop(columns=['label', '회계년도'], axis=1)\n",
    "    y_samp_test_1 = X_samp_test[['label']]\n",
    "\n",
    "    X_samp_train_1.reset_index(drop=True, inplace=True)\n",
    "    X_samp_test_1.reset_index(drop=True, inplace=True)\n",
    "    y_samp_train_1.reset_index(drop=True, inplace=True)\n",
    "    y_samp_test_1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "    X_samp_2, y_samp_2 = BorderlineSMOTE(random_state=0,sampling_strategy=1).fit_resample(X_samp_train_1, y_samp_train_1)\n",
    "\n",
    "    train_df = pd.concat([X_samp_2, y_samp_2], axis=1)\n",
    "    test_df = pd.concat([X_samp_test_1, y_samp_test_1], axis=1)\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    540\n",
       "1    540\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5(kk)[0]['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    85\n",
       "1    17\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5(kk)[1]['label'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6번 데이터 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model6(Data):\n",
    "\n",
    "    train = Data[(Data['회계년도'] <= '2019/12') & (Data['회계년도'] >= '2018/12') | (Data['회계년도'] >= '2011/12') & (Data['회계년도'] <= '2015/12')].reset_index(drop=True)\n",
    "    test = Data[(Data['회계년도'] <= '2017/12') & (Data['회계년도'] >= '2016/12')].reset_index(drop=True)\n",
    "\n",
    "    X_train = train.drop(columns=['label', '산업분류', '기업생애주기_Shake-Out',\n",
    "       '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도'], axis=1)\n",
    "    X_train_concat = train[['산업분류', '기업생애주기_Shake-Out',\n",
    "        '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도']]\n",
    "    y_train = train[['label']]\n",
    "    X_test = test.drop(columns=['label', '산업분류', '기업생애주기_Shake-Out',\n",
    "       '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도'], axis=1)\n",
    "    X_test_concat = test[['산업분류', '기업생애주기_Shake-Out',\n",
    "        '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도']]\n",
    "    y_test = test[['label']]\n",
    "\n",
    "\n",
    "    ## Scaling##\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    # StandardScaler() Scaler객체 생성.\n",
    "    scaler = StandardScaler()\n",
    "    # 학습 데이터에 대해서 fit(), transform() 수행.\n",
    "    scaler.fit(X_train)\n",
    "    train_scaled_SS = scaler.transform(X_train)\n",
    "    # transform()시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
    "    X_train_SS = pd.DataFrame(data = train_scaled_SS, columns=X_train.columns)\n",
    "\n",
    "    # 테스트 데이터에서는 다시 fit(), transform()이나 fit_transform()을 수행하지 않고 transform만 수행.\n",
    "    test_scaled_MM = scaler.transform(X_test)\n",
    "    # transform()시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
    "    X_test_SS = pd.DataFrame(data = test_scaled_MM, columns=X_test.columns)\n",
    "\n",
    "\n",
    "    X_train_SS = pd.concat([X_train_SS,X_train_concat,y_train], axis=1)\n",
    "    X_test_SS = pd.concat([X_test_SS,X_test_concat, y_test], axis=1)\n",
    "\n",
    "    trian_test_df = pd.concat([X_train_SS, X_test_SS], axis=0)\n",
    "    trian_test_df.reset_index(drop=True, inplace=True)      \n",
    "\n",
    "    df_2011 = trian_test_df[trian_test_df['회계년도'] == '2011/12']\n",
    "    df_2012 = trian_test_df[trian_test_df['회계년도'] == '2012/12']\n",
    "    df_2013 = trian_test_df[trian_test_df['회계년도'] == '2013/12']\n",
    "    df_2014 = trian_test_df[trian_test_df['회계년도'] == '2014/12']\n",
    "    df_2015 = trian_test_df[trian_test_df['회계년도'] == '2015/12']\n",
    "    df_2016 = trian_test_df[trian_test_df['회계년도'] == '2016/12']\n",
    "    df_2017 = trian_test_df[trian_test_df['회계년도'] == '2017/12']\n",
    "    df_2018 = trian_test_df[trian_test_df['회계년도'] == '2018/12']\n",
    "    df_2019 = trian_test_df[trian_test_df['회계년도'] == '2019/12']\n",
    "\n",
    "    df_X_2011 = df_2011.drop(columns='label', axis=1)\n",
    "    df_y_2011 = df_2011[['label']]\n",
    "    df_X_2012 = df_2012.drop(columns='label', axis=1)\n",
    "    df_y_2012 = df_2012[['label']]\n",
    "    df_X_2013 = df_2013.drop(columns='label', axis=1)\n",
    "    df_y_2013 = df_2013[['label']]\n",
    "    df_X_2014 = df_2014.drop(columns='label', axis=1)\n",
    "    df_y_2014 = df_2014[['label']]\n",
    "    df_X_2015 = df_2015.drop(columns='label', axis=1)\n",
    "    df_y_2015 = df_2015[['label']]\n",
    "    df_X_2016 = df_2016.drop(columns='label', axis=1)\n",
    "    df_y_2016 = df_2016[['label']]\n",
    "    df_X_2017 = df_2017.drop(columns='label', axis=1)\n",
    "    df_y_2017 = df_2017[['label']]\n",
    "    df_X_2018 = df_2018.drop(columns='label', axis=1)\n",
    "    df_y_2018 = df_2018[['label']]\n",
    "    df_X_2019 = df_2019.drop(columns='label', axis=1)\n",
    "    df_y_2019 = df_2019[['label']]\n",
    "    \n",
    "\n",
    "    ## UnderSampler ##\n",
    "\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "    X_samp_11, y_samp_11 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2011, df_y_2011)\n",
    "    X_samp_12, y_samp_12 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2012, df_y_2012)\n",
    "    X_samp_13, y_samp_13 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2013, df_y_2013)\n",
    "    X_samp_14, y_samp_14 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2014, df_y_2014)\n",
    "    X_samp_15, y_samp_15 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2015, df_y_2015)\n",
    "    X_samp_16, y_samp_16 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2016, df_y_2016)\n",
    "    X_samp_17, y_samp_17 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2017, df_y_2017)\n",
    "    X_samp_18, y_samp_18 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2018, df_y_2018)\n",
    "    X_samp_19, y_samp_19 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2019, df_y_2019)\n",
    "\n",
    "    X_samp = pd.concat([X_samp_11, X_samp_12, X_samp_13, X_samp_14, X_samp_15, X_samp_16, X_samp_17, X_samp_18, X_samp_19], axis=0)\n",
    "    y_samp = pd.concat([y_samp_11, y_samp_12, y_samp_13, y_samp_14, y_samp_15, y_samp_16, y_samp_17, y_samp_18, y_samp_19], axis=0)\n",
    "\n",
    "    a = pd.concat([X_samp, y_samp], axis=1)\n",
    "\n",
    "    # 교차검증 3 데이터 셋\n",
    "    X_samp_train = a[(a['회계년도'] <= '2019/12') & (a['회계년도'] >= '2018/12') | (a['회계년도'] >= '2011/12') & (a['회계년도'] <= '2015/12')]\n",
    "    X_samp_test = a[(a['회계년도'] <= '2017/12') & (a['회계년도'] >= '2016/12')]\n",
    "\n",
    "    X_samp_train_1 = X_samp_train.drop(columns=['label', '회계년도'], axis=1)\n",
    "    y_samp_train_1 = X_samp_train[['label']]\n",
    "\n",
    "    X_samp_test_1 = X_samp_test.drop(columns=['label', '회계년도'], axis=1)\n",
    "    y_samp_test_1 = X_samp_test[['label']]\n",
    "\n",
    "    X_samp_train_1.reset_index(drop=True, inplace=True)\n",
    "    X_samp_test_1.reset_index(drop=True, inplace=True)\n",
    "    y_samp_train_1.reset_index(drop=True, inplace=True)\n",
    "    y_samp_test_1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "    X_samp_2, y_samp_2 = BorderlineSMOTE(random_state=0,sampling_strategy=1).fit_resample(X_samp_train_1, y_samp_train_1)\n",
    "\n",
    "    train_df = pd.concat([X_samp_2, y_samp_2], axis=1)\n",
    "    test_df = pd.concat([X_samp_test_1, y_samp_test_1], axis=1)\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    535\n",
       "1    535\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6(kk)[0]['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    90\n",
       "1    18\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model6(kk)[1]['label'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7번 데이터 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model7(Data):\n",
    "\n",
    "    train = Data[(Data['회계년도'] == '2019/12') | (Data['회계년도'] >= '2011/12') & (Data['회계년도'] <= '2016/12')].reset_index(drop=True)\n",
    "    test = Data[(Data['회계년도'] <= '2018/12') & (Data['회계년도'] >= '2017/12')].reset_index(drop=True)\n",
    "\n",
    "    X_train = train.drop(columns=['label', '산업분류', '기업생애주기_Shake-Out',\n",
    "       '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도'], axis=1)\n",
    "    X_train_concat = train[['산업분류', '기업생애주기_Shake-Out',\n",
    "        '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도']]\n",
    "    y_train = train[['label']]\n",
    "    X_test = test.drop(columns=['label', '산업분류', '기업생애주기_Shake-Out',\n",
    "       '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도'], axis=1)\n",
    "    X_test_concat = test[['산업분류', '기업생애주기_Shake-Out',\n",
    "        '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도']]\n",
    "    y_test = test[['label']]\n",
    "\n",
    "\n",
    "    ## Scaling##\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    # StandardScaler() Scaler객체 생성.\n",
    "    scaler = StandardScaler()\n",
    "    # 학습 데이터에 대해서 fit(), transform() 수행.\n",
    "    scaler.fit(X_train)\n",
    "    train_scaled_SS = scaler.transform(X_train)\n",
    "    # transform()시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
    "    X_train_SS = pd.DataFrame(data = train_scaled_SS, columns=X_train.columns)\n",
    "\n",
    "    # 테스트 데이터에서는 다시 fit(), transform()이나 fit_transform()을 수행하지 않고 transform만 수행.\n",
    "    test_scaled_MM = scaler.transform(X_test)\n",
    "    # transform()시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
    "    X_test_SS = pd.DataFrame(data = test_scaled_MM, columns=X_test.columns)\n",
    "\n",
    "\n",
    "    X_train_SS = pd.concat([X_train_SS,X_train_concat,y_train], axis=1)\n",
    "    X_test_SS = pd.concat([X_test_SS,X_test_concat, y_test], axis=1)\n",
    "\n",
    "    trian_test_df = pd.concat([X_train_SS, X_test_SS], axis=0)\n",
    "    trian_test_df.reset_index(drop=True, inplace=True)      \n",
    "\n",
    "    df_2011 = trian_test_df[trian_test_df['회계년도'] == '2011/12']\n",
    "    df_2012 = trian_test_df[trian_test_df['회계년도'] == '2012/12']\n",
    "    df_2013 = trian_test_df[trian_test_df['회계년도'] == '2013/12']\n",
    "    df_2014 = trian_test_df[trian_test_df['회계년도'] == '2014/12']\n",
    "    df_2015 = trian_test_df[trian_test_df['회계년도'] == '2015/12']\n",
    "    df_2016 = trian_test_df[trian_test_df['회계년도'] == '2016/12']\n",
    "    df_2017 = trian_test_df[trian_test_df['회계년도'] == '2017/12']\n",
    "    df_2018 = trian_test_df[trian_test_df['회계년도'] == '2018/12']\n",
    "    df_2019 = trian_test_df[trian_test_df['회계년도'] == '2019/12']\n",
    "\n",
    "    df_X_2011 = df_2011.drop(columns='label', axis=1)\n",
    "    df_y_2011 = df_2011[['label']]\n",
    "    df_X_2012 = df_2012.drop(columns='label', axis=1)\n",
    "    df_y_2012 = df_2012[['label']]\n",
    "    df_X_2013 = df_2013.drop(columns='label', axis=1)\n",
    "    df_y_2013 = df_2013[['label']]\n",
    "    df_X_2014 = df_2014.drop(columns='label', axis=1)\n",
    "    df_y_2014 = df_2014[['label']]\n",
    "    df_X_2015 = df_2015.drop(columns='label', axis=1)\n",
    "    df_y_2015 = df_2015[['label']]\n",
    "    df_X_2016 = df_2016.drop(columns='label', axis=1)\n",
    "    df_y_2016 = df_2016[['label']]\n",
    "    df_X_2017 = df_2017.drop(columns='label', axis=1)\n",
    "    df_y_2017 = df_2017[['label']]\n",
    "    df_X_2018 = df_2018.drop(columns='label', axis=1)\n",
    "    df_y_2018 = df_2018[['label']]\n",
    "    df_X_2019 = df_2019.drop(columns='label', axis=1)\n",
    "    df_y_2019 = df_2019[['label']]\n",
    "    \n",
    "\n",
    "    ## UnderSampler ##\n",
    "\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "    X_samp_11, y_samp_11 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2011, df_y_2011)\n",
    "    X_samp_12, y_samp_12 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2012, df_y_2012)\n",
    "    X_samp_13, y_samp_13 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2013, df_y_2013)\n",
    "    X_samp_14, y_samp_14 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2014, df_y_2014)\n",
    "    X_samp_15, y_samp_15 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2015, df_y_2015)\n",
    "    X_samp_16, y_samp_16 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2016, df_y_2016)\n",
    "    X_samp_17, y_samp_17 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2017, df_y_2017)\n",
    "    X_samp_18, y_samp_18 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2018, df_y_2018)\n",
    "    X_samp_19, y_samp_19 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2019, df_y_2019)\n",
    "\n",
    "    X_samp = pd.concat([X_samp_11, X_samp_12, X_samp_13, X_samp_14, X_samp_15, X_samp_16, X_samp_17, X_samp_18, X_samp_19], axis=0)\n",
    "    y_samp = pd.concat([y_samp_11, y_samp_12, y_samp_13, y_samp_14, y_samp_15, y_samp_16, y_samp_17, y_samp_18, y_samp_19], axis=0)\n",
    "\n",
    "    a = pd.concat([X_samp, y_samp], axis=1)\n",
    "\n",
    "    # 교차검증 3 데이터 셋\n",
    "    X_samp_train = a[(a['회계년도'] == '2019/12') | (a['회계년도'] >= '2011/12') & (a['회계년도'] <= '2016/12')]\n",
    "    X_samp_test = a[(a['회계년도'] <= '2018/12') & (a['회계년도'] >= '2017/12')]\n",
    "\n",
    "    X_samp_train_1 = X_samp_train.drop(columns=['label', '회계년도'], axis=1)\n",
    "    y_samp_train_1 = X_samp_train[['label']]\n",
    "\n",
    "    X_samp_test_1 = X_samp_test.drop(columns=['label', '회계년도'], axis=1)\n",
    "    y_samp_test_1 = X_samp_test[['label']]\n",
    "\n",
    "    X_samp_train_1.reset_index(drop=True, inplace=True)\n",
    "    X_samp_test_1.reset_index(drop=True, inplace=True)\n",
    "    y_samp_train_1.reset_index(drop=True, inplace=True)\n",
    "    y_samp_test_1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "    X_samp_2, y_samp_2 = BorderlineSMOTE(random_state=0,sampling_strategy=1).fit_resample(X_samp_train_1, y_samp_train_1)\n",
    "\n",
    "    train_df = pd.concat([X_samp_2, y_samp_2], axis=1)\n",
    "    test_df = pd.concat([X_samp_test_1, y_samp_test_1], axis=1)\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    540\n",
       "1    540\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7(kk)[0]['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    85\n",
       "1    17\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model7(kk)[1]['label'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0번 데이터 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model0(Data):\n",
    "\n",
    "    train = Data[(Data['회계년도'] <= '2017/12') & (Data['회계년도'] >= '2011/12')].reset_index(drop=True)\n",
    "    test = Data[(Data['회계년도'] <= '2019/12') & (Data['회계년도'] >= '2018/12')].reset_index(drop=True)\n",
    "\n",
    "    ## Train Scaling 전 Data 분리하기 ##\n",
    "\n",
    "    X_train = train.drop(columns=['label', '산업분류', '기업생애주기_Shake-Out',\n",
    "       '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도'], axis=1)\n",
    "    X_train_concat = train[['산업분류', '기업생애주기_Shake-Out',\n",
    "        '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도']]\n",
    "    y_train = train[['label']]\n",
    "    X_test = test.drop(columns=['label', '산업분류', '기업생애주기_Shake-Out',\n",
    "       '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도'], axis=1)\n",
    "    X_test_concat = test[['산업분류', '기업생애주기_Shake-Out',\n",
    "        '기업생애주기_도입기', '기업생애주기_성숙기', '기업생애주기_성장기', '기업생애주기_쇠퇴기', '회계년도']]\n",
    "    y_test = test[['label']]\n",
    "\n",
    "\n",
    "    ## Scaling##\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    # StandardScaler() Scaler객체 생성.\n",
    "    scaler = StandardScaler()\n",
    "    # 학습 데이터에 대해서 fit(), transform() 수행.\n",
    "    scaler.fit(X_train)\n",
    "    train_scaled_SS = scaler.transform(X_train)\n",
    "    # transform()시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
    "    X_train_SS = pd.DataFrame(data = train_scaled_SS, columns=X_train.columns)\n",
    "\n",
    "    # 테스트 데이터에서는 다시 fit(), transform()이나 fit_transform()을 수행하지 않고 transform만 수행.\n",
    "    test_scaled_MM = scaler.transform(X_test)\n",
    "    # transform()시 scale 변환된 데이터 셋이 numpy ndarry로 반환되어 이를 DataFrame으로 변환\n",
    "    X_test_SS = pd.DataFrame(data = test_scaled_MM, columns=X_test.columns)\n",
    "\n",
    "\n",
    "    X_train_SS = pd.concat([X_train_SS,X_train_concat,y_train], axis=1)\n",
    "    X_test_SS = pd.concat([X_test_SS,X_test_concat, y_test], axis=1)\n",
    "\n",
    "    trian_test_df = pd.concat([X_train_SS, X_test_SS], axis=0)\n",
    "    trian_test_df.reset_index(drop=True, inplace=True)      \n",
    "\n",
    "    df_2011 = trian_test_df[trian_test_df['회계년도'] == '2011/12']\n",
    "    df_2012 = trian_test_df[trian_test_df['회계년도'] == '2012/12']\n",
    "    df_2013 = trian_test_df[trian_test_df['회계년도'] == '2013/12']\n",
    "    df_2014 = trian_test_df[trian_test_df['회계년도'] == '2014/12']\n",
    "    df_2015 = trian_test_df[trian_test_df['회계년도'] == '2015/12']\n",
    "    df_2016 = trian_test_df[trian_test_df['회계년도'] == '2016/12']\n",
    "    df_2017 = trian_test_df[trian_test_df['회계년도'] == '2017/12']\n",
    "    df_2018 = trian_test_df[trian_test_df['회계년도'] == '2018/12']\n",
    "    df_2019 = trian_test_df[trian_test_df['회계년도'] == '2019/12']\n",
    "\n",
    "    df_X_2011 = df_2011.drop(columns='label', axis=1)\n",
    "    df_y_2011 = df_2011[['label']]\n",
    "    df_X_2012 = df_2012.drop(columns='label', axis=1)\n",
    "    df_y_2012 = df_2012[['label']]\n",
    "    df_X_2013 = df_2013.drop(columns='label', axis=1)\n",
    "    df_y_2013 = df_2013[['label']]\n",
    "    df_X_2014 = df_2014.drop(columns='label', axis=1)\n",
    "    df_y_2014 = df_2014[['label']]\n",
    "    df_X_2015 = df_2015.drop(columns='label', axis=1)\n",
    "    df_y_2015 = df_2015[['label']]\n",
    "    df_X_2016 = df_2016.drop(columns='label', axis=1)\n",
    "    df_y_2016 = df_2016[['label']]\n",
    "    df_X_2017 = df_2017.drop(columns='label', axis=1)\n",
    "    df_y_2017 = df_2017[['label']]\n",
    "    df_X_2018 = df_2018.drop(columns='label', axis=1)\n",
    "    df_y_2018 = df_2018[['label']]\n",
    "    df_X_2019 = df_2019.drop(columns='label', axis=1)\n",
    "    df_y_2019 = df_2019[['label']]\n",
    "    \n",
    "\n",
    "    ## UnderSampler ##\n",
    "\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "    X_samp_11, y_samp_11 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2011, df_y_2011)\n",
    "    X_samp_12, y_samp_12 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2012, df_y_2012)\n",
    "    X_samp_13, y_samp_13 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2013, df_y_2013)\n",
    "    X_samp_14, y_samp_14 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2014, df_y_2014)\n",
    "    X_samp_15, y_samp_15 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2015, df_y_2015)\n",
    "    X_samp_16, y_samp_16 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2016, df_y_2016)\n",
    "    X_samp_17, y_samp_17 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2017, df_y_2017)\n",
    "    X_samp_18, y_samp_18 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2018, df_y_2018)\n",
    "    X_samp_19, y_samp_19 = RandomUnderSampler(random_state=0,sampling_strategy=0.2).fit_resample(df_X_2019, df_y_2019)\n",
    "\n",
    "    X_samp = pd.concat([X_samp_11, X_samp_12, X_samp_13, X_samp_14, X_samp_15, X_samp_16, X_samp_17, X_samp_18, X_samp_19], axis=0)\n",
    "    y_samp = pd.concat([y_samp_11, y_samp_12, y_samp_13, y_samp_14, y_samp_15, y_samp_16, y_samp_17, y_samp_18, y_samp_19], axis=0)\n",
    "\n",
    "    trian_test_samp_df = pd.concat([X_samp, y_samp], axis=1)\n",
    "\n",
    "    # 교차검증 1 데이터 셋\n",
    "    X_samp_train = trian_test_samp_df[(trian_test_samp_df['회계년도'] <= '2017/12') & (trian_test_samp_df['회계년도'] >= '2011/12')]\n",
    "    X_samp_test = trian_test_samp_df[(trian_test_samp_df['회계년도'] <= '2019/12') & (trian_test_samp_df['회계년도'] >= '2018/12')]\n",
    "\n",
    "    X_samp_train_1 = X_samp_train.drop(columns=['label', '회계년도'], axis=1)\n",
    "    y_samp_train_1 = X_samp_train[['label']]\n",
    "\n",
    "    X_samp_test_1 = X_samp_test.drop(columns=['label', '회계년도'], axis=1)\n",
    "    y_samp_test_1 = X_samp_test[['label']]\n",
    "\n",
    "    X_samp_train_1.reset_index(drop=True, inplace=True)\n",
    "    X_samp_test_1.reset_index(drop=True, inplace=True)\n",
    "    y_samp_train_1.reset_index(drop=True, inplace=True)\n",
    "    y_samp_test_1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "    X_samp_2, y_samp_2 = BorderlineSMOTE(random_state=0,sampling_strategy=1).fit_resample(X_samp_train_1, y_samp_train_1)\n",
    "\n",
    "    train_df = pd.concat([X_samp_2, y_samp_2], axis=1)\n",
    "    test_df = pd.concat([X_samp_test_1, y_samp_test_1], axis=1)\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    535\n",
       "1    535\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0(kk)[0]['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    90\n",
       "1    18\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0(kk)[1]['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1 = model1(kk)[0].drop(columns=['label'], axis=1)\n",
    "y_train_1 = model1(kk)[0][['label']]\n",
    "X_test_1 = model1(kk)[1].drop(columns=['label'], axis=1)\n",
    "y_test_1 = model1(kk)[1][['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = model2(kk)[0].drop(columns=['label'], axis=1)\n",
    "y_train_2 = model2(kk)[0][['label']]\n",
    "X_test_2 = model2(kk)[1].drop(columns=['label'], axis=1)\n",
    "y_test_2 = model2(kk)[1][['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3 = model3(kk)[0].drop(columns=['label'], axis=1)\n",
    "y_train_3 = model3(kk)[0][['label']]\n",
    "X_test_3 = model3(kk)[1].drop(columns=['label'], axis=1)\n",
    "y_test_3 = model3(kk)[1][['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_4 = model4(kk)[0].drop(columns=['label'], axis=1)\n",
    "y_train_4 = model4(kk)[0][['label']]\n",
    "X_test_4 = model4(kk)[1].drop(columns=['label'], axis=1)\n",
    "y_test_4 = model4(kk)[1][['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_5 = model5(kk)[0].drop(columns=['label'], axis=1)\n",
    "y_train_5 = model5(kk)[0][['label']]\n",
    "X_test_5 = model5(kk)[1].drop(columns=['label'], axis=1)\n",
    "y_test_5 = model5(kk)[1][['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_6 = model6(kk)[0].drop(columns=['label'], axis=1)\n",
    "y_train_6 = model6(kk)[0][['label']]\n",
    "X_test_6 = model6(kk)[1].drop(columns=['label'], axis=1)\n",
    "y_test_6 = model6(kk)[1][['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_7 = model7(kk)[0].drop(columns=['label'], axis=1)\n",
    "y_train_7 = model7(kk)[0][['label']]\n",
    "X_test_7 = model7(kk)[1].drop(columns=['label'], axis=1)\n",
    "y_test_7 = model7(kk)[1][['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_basic(x_train, y_train, x_test, y_test): \n",
    "    models = [\n",
    "        LogisticRegression(random_state=0),\n",
    "        SVC(random_state=0),\n",
    "        DecisionTreeClassifier(random_state=0),\n",
    "        RandomForestClassifier(random_state=0),\n",
    "        XGBClassifier(random_state=0),\n",
    "        LGBMClassifier(random_state=0) \n",
    "    ]\n",
    "\n",
    "    rdict={'model':[],'acc_train':[], 'auc_train':[], 'acc_test':[],'precision':[],'recall':[],'f1_score':[], 'AUC_test':[]}\n",
    "\n",
    "\n",
    "    for clf in models:\n",
    "        clf = clf.fit(x_train, y_train)\n",
    "    #1열:Train\n",
    "        y_hat = clf.predict(x_train)\n",
    "        results_train  = (round(accuracy_score(y_train,y_hat),2),round(roc_auc_score(y_train,y_hat),2))\n",
    "    #2열:Test\n",
    "        y_hat = clf.predict(x_test)\n",
    "        results = (round(accuracy_score(y_test,y_hat),2),\n",
    "                        round(precision_score(y_test,y_hat),2),\n",
    "                        round(recall_score(y_test,y_hat),2),\n",
    "                        round(f1_score(y_test,y_hat),2),\n",
    "                        round(roc_auc_score(y_test,y_hat),2))\n",
    "\n",
    "        rdict['model'].append(clf); \n",
    "        rdict['acc_train'].append(results_train[0])\n",
    "        rdict['auc_train'].append(results_train[1])\n",
    "        \n",
    "        rdict['acc_test'].append(results[0])\n",
    "        rdict['precision'].append(results[1])\n",
    "        rdict['recall'].append(results[2])\n",
    "        rdict['f1_score'].append(results[3])\n",
    "        rdict['AUC_test'].append(results[4])   \n",
    "\n",
    "        # confusion = confusion_matrix(y_test, y_hat)\n",
    "\n",
    "        # print(confusion)\n",
    "\n",
    "    rdf_final = pd.DataFrame(data=rdict)\n",
    "    return rdf_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_0 = model_basic(X_train_1, y_train_1, X_test_1, y_test_1).iloc[0]\n",
    "a_1 = model_basic(X_train_1, y_train_1, X_test_1, y_test_1).iloc[1]\n",
    "a_2 = model_basic(X_train_1, y_train_1, X_test_1, y_test_1).iloc[2]\n",
    "a_3 = model_basic(X_train_1, y_train_1, X_test_1, y_test_1).iloc[3]\n",
    "a_4 = model_basic(X_train_1, y_train_1, X_test_1, y_test_1).iloc[4]\n",
    "a_5 = model_basic(X_train_1, y_train_1, X_test_1, y_test_1).iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_0 = model_basic(X_train_2, y_train_2, X_test_2, y_test_2).iloc[0]\n",
    "b_1 = model_basic(X_train_2, y_train_2, X_test_2, y_test_2).iloc[1]\n",
    "b_2 = model_basic(X_train_2, y_train_2, X_test_2, y_test_2).iloc[2]\n",
    "b_3 = model_basic(X_train_2, y_train_2, X_test_2, y_test_2).iloc[3]\n",
    "b_4 = model_basic(X_train_2, y_train_2, X_test_2, y_test_2).iloc[4]\n",
    "b_5 = model_basic(X_train_2, y_train_2, X_test_2, y_test_2).iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_0 = model_basic(X_train_3, y_train_3, X_test_3, y_test_3).iloc[0]\n",
    "c_1 = model_basic(X_train_3, y_train_3, X_test_3, y_test_3).iloc[1]\n",
    "c_2 = model_basic(X_train_3, y_train_3, X_test_3, y_test_3).iloc[2]\n",
    "c_3 = model_basic(X_train_3, y_train_3, X_test_3, y_test_3).iloc[3]\n",
    "c_4 = model_basic(X_train_3, y_train_3, X_test_3, y_test_3).iloc[4]\n",
    "c_5 = model_basic(X_train_3, y_train_3, X_test_3, y_test_3).iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_0 = model_basic(X_train_4, y_train_4, X_test_4, y_test_4).iloc[0]\n",
    "d_1 = model_basic(X_train_4, y_train_4, X_test_4, y_test_4).iloc[1]\n",
    "d_2 = model_basic(X_train_4, y_train_4, X_test_4, y_test_4).iloc[2]\n",
    "d_3 = model_basic(X_train_4, y_train_4, X_test_4, y_test_4).iloc[3]\n",
    "d_4 = model_basic(X_train_4, y_train_4, X_test_4, y_test_4).iloc[4]\n",
    "d_5 = model_basic(X_train_4, y_train_4, X_test_4, y_test_4).iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_0 = model_basic(X_train_5, y_train_5, X_test_5, y_test_5).iloc[0]\n",
    "e_1 = model_basic(X_train_5, y_train_5, X_test_5, y_test_5).iloc[1]\n",
    "e_2 = model_basic(X_train_5, y_train_5, X_test_5, y_test_5).iloc[2]\n",
    "e_3 = model_basic(X_train_5, y_train_5, X_test_5, y_test_5).iloc[3]\n",
    "e_4 = model_basic(X_train_5, y_train_5, X_test_5, y_test_5).iloc[4]\n",
    "e_5 = model_basic(X_train_5, y_train_5, X_test_5, y_test_5).iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_0 = model_basic(X_train_6, y_train_6, X_test_6, y_test_6).iloc[0]\n",
    "f_1 = model_basic(X_train_6, y_train_6, X_test_6, y_test_6).iloc[1]\n",
    "f_2 = model_basic(X_train_6, y_train_6, X_test_6, y_test_6).iloc[2]\n",
    "f_3 = model_basic(X_train_6, y_train_6, X_test_6, y_test_6).iloc[3]\n",
    "f_4 = model_basic(X_train_6, y_train_6, X_test_6, y_test_6).iloc[4]\n",
    "f_5 = model_basic(X_train_6, y_train_6, X_test_6, y_test_6).iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_0 = model_basic(X_train_7, y_train_7, X_test_7, y_test_7).iloc[0]\n",
    "g_1 = model_basic(X_train_7, y_train_7, X_test_7, y_test_7).iloc[1]\n",
    "g_2 = model_basic(X_train_7, y_train_7, X_test_7, y_test_7).iloc[2]\n",
    "g_3 = model_basic(X_train_7, y_train_7, X_test_7, y_test_7).iloc[3]\n",
    "g_4 = model_basic(X_train_7, y_train_7, X_test_7, y_test_7).iloc[4]\n",
    "g_5 = model_basic(X_train_7, y_train_7, X_test_7, y_test_7).iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Logistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.968571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc_train</th>\n",
       "      <td>0.968571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_test</th>\n",
       "      <td>0.861429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Logistic\n",
       "acc_train  0.968571\n",
       "auc_train  0.968571\n",
       "acc_test   0.910000\n",
       "precision  0.714286\n",
       "recall     0.790000\n",
       "f1_score   0.750000\n",
       "AUC_test   0.861429"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = pd.DataFrame(a_0)\n",
    "df_1 = pd.DataFrame(b_0)\n",
    "df_2 = pd.DataFrame(c_0)\n",
    "df_3 = pd.DataFrame(d_0)\n",
    "df_4 = pd.DataFrame(e_0)\n",
    "df_5 = pd.DataFrame(f_0)\n",
    "df_6 = pd.DataFrame(e_0)\n",
    "\n",
    "df = pd.concat([df_0, df_1, df_2, df_3, df_4, df_5, df_6], axis=1)\n",
    "# 첫 번째 행을 컬럼으로 옮기기\n",
    "df.columns = df.iloc[0]\n",
    "df = df.iloc[1:]\n",
    "dfdf1 = pd.DataFrame(df.T.mean())\n",
    "dfdf1.columns = ['Logistic']\n",
    "dfdf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>0.972857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc_train</th>\n",
       "      <td>0.972857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.724286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.762857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_test</th>\n",
       "      <td>0.851429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                SVC\n",
       "acc_train  0.972857\n",
       "auc_train  0.972857\n",
       "acc_test   0.910000\n",
       "precision  0.724286\n",
       "recall     0.762857\n",
       "f1_score   0.742857\n",
       "AUC_test   0.851429"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = pd.DataFrame(a_1)\n",
    "df_1 = pd.DataFrame(b_1)\n",
    "df_2 = pd.DataFrame(c_1)\n",
    "df_3 = pd.DataFrame(d_1)\n",
    "df_4 = pd.DataFrame(e_1)\n",
    "df_5 = pd.DataFrame(f_1)\n",
    "df_6 = pd.DataFrame(e_1)\n",
    "\n",
    "df = pd.concat([df_0, df_1, df_2, df_3, df_4, df_5, df_6], axis=1)\n",
    "# 첫 번째 행을 컬럼으로 옮기기\n",
    "df.columns = df.iloc[0]\n",
    "df = df.iloc[1:]\n",
    "dfdf2 = pd.DataFrame(df.T.mean())\n",
    "dfdf2.columns = ['SVC']\n",
    "dfdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DecisionTree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc_train</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.647143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.768571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_test</th>\n",
       "      <td>0.841429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DecisionTree\n",
       "acc_train      1.000000\n",
       "auc_train      1.000000\n",
       "acc_test       0.890000\n",
       "precision      0.647143\n",
       "recall         0.768571\n",
       "f1_score       0.700000\n",
       "AUC_test       0.841429"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = pd.DataFrame(a_2)\n",
    "df_1 = pd.DataFrame(b_2)\n",
    "df_2 = pd.DataFrame(c_2)\n",
    "df_3 = pd.DataFrame(d_2)\n",
    "df_4 = pd.DataFrame(e_2)\n",
    "df_5 = pd.DataFrame(f_2)\n",
    "df_6 = pd.DataFrame(e_2)\n",
    "\n",
    "df = pd.concat([df_0, df_1, df_2, df_3, df_4, df_5, df_6], axis=1)\n",
    "# 첫 번째 행을 컬럼으로 옮기기\n",
    "df.columns = df.iloc[0]\n",
    "df = df.iloc[1:]\n",
    "dfdf3 = pd.DataFrame(df.T.mean())\n",
    "dfdf3.columns = ['DecisionTree']\n",
    "dfdf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc_train</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.924286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.742857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.791429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_test</th>\n",
       "      <td>0.897143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           RandomForest\n",
       "acc_train      1.000000\n",
       "auc_train      1.000000\n",
       "acc_test       0.924286\n",
       "precision      0.742857\n",
       "recall         0.850000\n",
       "f1_score       0.791429\n",
       "AUC_test       0.897143"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = pd.DataFrame(a_3)\n",
    "df_1 = pd.DataFrame(b_3)\n",
    "df_2 = pd.DataFrame(c_3)\n",
    "df_3 = pd.DataFrame(d_3)\n",
    "df_4 = pd.DataFrame(e_3)\n",
    "df_5 = pd.DataFrame(f_3)\n",
    "df_6 = pd.DataFrame(e_3)\n",
    "\n",
    "df = pd.concat([df_0, df_1, df_2, df_3, df_4, df_5, df_6], axis=1)\n",
    "# 첫 번째 행을 컬럼으로 옮기기\n",
    "df.columns = df.iloc[0]\n",
    "df = df.iloc[1:]\n",
    "dfdf4 = pd.DataFrame(df.T.mean())\n",
    "dfdf4.columns = ['RandomForest']\n",
    "dfdf4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XGB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc_train</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.918571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.731429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.821429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.772857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_test</th>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                XGB\n",
       "acc_train  1.000000\n",
       "auc_train  1.000000\n",
       "acc_test   0.918571\n",
       "precision  0.731429\n",
       "recall     0.821429\n",
       "f1_score   0.772857\n",
       "AUC_test   0.880000"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = pd.DataFrame(a_4)\n",
    "df_1 = pd.DataFrame(b_4)\n",
    "df_2 = pd.DataFrame(c_4)\n",
    "df_3 = pd.DataFrame(d_4)\n",
    "df_4 = pd.DataFrame(e_4)\n",
    "df_5 = pd.DataFrame(f_4)\n",
    "df_6 = pd.DataFrame(e_4)\n",
    "\n",
    "df = pd.concat([df_0, df_1, df_2, df_3, df_4, df_5, df_6], axis=1)\n",
    "# 첫 번째 행을 컬럼으로 옮기기\n",
    "df.columns = df.iloc[0]\n",
    "df = df.iloc[1:]\n",
    "dfdf5 = pd.DataFrame(df.T.mean())\n",
    "dfdf5.columns = ['XGB']\n",
    "dfdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LGBM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc_train</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc_train</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc_test</th>\n",
       "      <td>0.925714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.821429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.788571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC_test</th>\n",
       "      <td>0.884286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               LGBM\n",
       "acc_train  1.000000\n",
       "auc_train  1.000000\n",
       "acc_test   0.925714\n",
       "precision  0.757143\n",
       "recall     0.821429\n",
       "f1_score   0.788571\n",
       "AUC_test   0.884286"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_0 = pd.DataFrame(a_5)\n",
    "df_1 = pd.DataFrame(b_5)\n",
    "df_2 = pd.DataFrame(c_5)\n",
    "df_3 = pd.DataFrame(d_5)\n",
    "df_4 = pd.DataFrame(e_5)\n",
    "df_5 = pd.DataFrame(f_5)\n",
    "df_6 = pd.DataFrame(e_5)\n",
    "\n",
    "df = pd.concat([df_0, df_1, df_2, df_3, df_4, df_5, df_6], axis=1)\n",
    "# 첫 번째 행을 컬럼으로 옮기기\n",
    "df.columns = df.iloc[0]\n",
    "df = df.iloc[1:]\n",
    "dfdf6 = pd.DataFrame(df.T.mean())\n",
    "dfdf6.columns = ['LGBM']\n",
    "dfdf6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_train</th>\n",
       "      <th>auc_train</th>\n",
       "      <th>acc_test</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>AUC_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic</th>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.7143</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.8614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.9729</td>\n",
       "      <td>0.9729</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.7243</td>\n",
       "      <td>0.7629</td>\n",
       "      <td>0.7429</td>\n",
       "      <td>0.8514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.6471</td>\n",
       "      <td>0.7686</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.8414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9243</td>\n",
       "      <td>0.7429</td>\n",
       "      <td>0.8500</td>\n",
       "      <td>0.7914</td>\n",
       "      <td>0.8971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9186</td>\n",
       "      <td>0.7314</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>0.7729</td>\n",
       "      <td>0.8800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9257</td>\n",
       "      <td>0.7571</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>0.7886</td>\n",
       "      <td>0.8843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              acc_train  auc_train  acc_test  precision  recall  f1_score  \\\n",
       "Logistic         0.9686     0.9686    0.9100     0.7143  0.7900    0.7500   \n",
       "SVC              0.9729     0.9729    0.9100     0.7243  0.7629    0.7429   \n",
       "DecisionTree     1.0000     1.0000    0.8900     0.6471  0.7686    0.7000   \n",
       "RandomForest     1.0000     1.0000    0.9243     0.7429  0.8500    0.7914   \n",
       "XGB              1.0000     1.0000    0.9186     0.7314  0.8214    0.7729   \n",
       "LGBM             1.0000     1.0000    0.9257     0.7571  0.8214    0.7886   \n",
       "\n",
       "              AUC_test  \n",
       "Logistic        0.8614  \n",
       "SVC             0.8514  \n",
       "DecisionTree    0.8414  \n",
       "RandomForest    0.8971  \n",
       "XGB             0.8800  \n",
       "LGBM            0.8843  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kosdaqkospi_교차검증평균 = round(pd.concat([dfdf1,dfdf2,dfdf3,dfdf4,dfdf5,dfdf6], axis=1),4)\n",
    "kosdaqkospi_교차검증평균.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
